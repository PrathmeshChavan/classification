# -*- coding: utf-8 -*-
"""model tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DbmzWW1Jk_3i3-8t8to-2RNG0DvlQmuy

## In This Model Tuning.ipynb File I will Use 2 Data Files
* 1 - preprocessed_Online+offline_bining_used As My training data (8800 Records)
* 2 - preprocessed_Validation_offline_customers As My prediction set ( 50,000 Records)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
#from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, log_loss, brier_score_loss
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE

# Reading our SAMPLED_Online+offline_bining_used file. I will Use this file for model training
df = pd.read_csv('/content/drive/MyDrive/Kaam/preprocessed_Online+offline_bining_used.csv')
df.head()

"""## Checking Performance Without Hyperparameters"""

# Train Test Split
x=df.drop('CHANNEL' , axis = 1)
y=df.CHANNEL
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 2)

# LogisticRegression
pipeline_lr=Pipeline([('over1' , SMOTE(random_state=45)),
                      ('scalar1',StandardScaler()),
                      ('lr_classifier',LogisticRegression(random_state=0))])   
# RandomForestClassifier
pipeline_rf=Pipeline([('over2' , SMOTE(random_state=45)),
                      ('scalar2',StandardScaler()),
                      ('rf_classifier',RandomForestClassifier())])              
 # XGBClassifier
pipeline_xg=Pipeline([('over3' , SMOTE(random_state=45)),
                      ('scalar3',StandardScaler()),
                      ('xg_classifier',XGBClassifier())])
# Lets make the list of pipelines
pipelines = [pipeline_lr, pipeline_rf, pipeline_xg]

# Dictionary of pipelines and classifier types for ease of reference
pipe_dict = {0: 'Logistic Regression', 1: 'RandomForest', 2: 'XGBoost'}

# Fit the pipelines
for pipe in pipelines:
	pipe.fit(x_train, y_train)

for i,model in enumerate(pipelines):
    prob=model.predict_proba(x_test)
    score= log_loss(y_test, prob)
    print("{} Log Loss Score : {}".format(pipe_dict[i],score))

for i,model in enumerate(pipelines):
    prob_brier=model.predict_proba(x_test)
    prob_brier=prob_brier[:,1]
    score_brier= brier_score_loss(y_test, prob_brier)
    print("{} Brier Score : {}".format(pipe_dict[i],score_brier))

# Logistic Regression confusion matrix
#y_pred = pipeline_lr.predict(x_test)
#lr_cm = confusion_matrix(y_test , y_pred)
#print("Logistic Regression confusion matrix :\n" , lr_cm )
#-----------------------------------------------------------------------------------------------------
# RandomForest confusion matrix
#y_pred = pipeline_rf.predict(x_test)
#rf_cm = confusion_matrix(y_test , y_pred)
#print("RandomForest  confusion matrix :\n " , rf_cm )
#-----------------------------------------------------------------------------------------------------
# XGBoost confusion matrix
#y_pred = pipeline_lr.predict(x_test)
#xg_cm = confusion_matrix(y_test , y_pred)
#print("XGBoost confusion matrix :\n " , xg_cm )

"""## Finding Best Hyper Parameters Using **GridSearchCV**"""

from sklearn.model_selection import GridSearchCV

# LogisticRegression

pipe_lr = Pipeline([('over_lr' , SMOTE(random_state=45)),('scalar_lr',StandardScaler()),("classifier", LogisticRegression())])

lr_para = {"classifier": [LogisticRegression()],
           "classifier__penalty": ['l2'],
           "classifier__C": np.logspace(0, 4, 10),
           "classifier__solver":['newton-cg','saga','sag','liblinear'] }


gridsearch_lr = GridSearchCV(pipe_lr, lr_para, cv=5, scoring="neg_log_loss",verbose=0,n_jobs=-1) # Fit grid search
best_model_lr = gridsearch_lr.fit(x_train,y_train)
print("Best Log Loss Score is " , best_model_lr.best_score_)
print("Best HyperParameters Are" , best_model_lr.best_estimator_)

# RandomForestClassifier

pipe_rf = Pipeline([('over_rf' , SMOTE(random_state=45)),('scalar_rf',StandardScaler()),("classifier", RandomForestClassifier())])

rf_para = {"classifier": [RandomForestClassifier()],
           "classifier__n_estimators": [100, 200 , 300],
           "classifier__max_depth":[5,8,15,25,None],
           "classifier__min_samples_leaf":[1,2,5,7],
           "classifier__max_leaf_nodes": [None,2,5,6]}


gridsearch_rf = GridSearchCV(pipe_rf, rf_para, scoring="neg_log_loss",cv=5, verbose=0,n_jobs=-1) # Fit grid search
best_model_rf = gridsearch_rf.fit(x_train,y_train)
print("Best Log Loss Score is " , best_model_rf.best_score_)
print("Best HyperParameters Are" , best_model_rf.best_estimator_)

# XGBClassifier

pipe_xg = Pipeline([('over_xg' , SMOTE(random_state=45)),('scalar_xg',StandardScaler()),("classifier", XGBClassifier())])

xg_para = {      "classifier":[XGBClassifier()],
                 "classifier__learning_rate" : [0.05 , 0.10 ],
                 "classifier__max_depth" : [3,4,5,6],        
                 "classifier__gamma" : [0.0, 0.1,0.2],
                 "classifier__colsample_bytree" : [0.3, 0.4,]}

gridsearch_xg = GridSearchCV(pipe_xg, xg_para, scoring="neg_log_loss" ,cv=5, verbose=0,n_jobs=-1) # Fit grid search
best_model_xg = gridsearch_xg.fit(x_train,y_train)
print("Best Log Loss Score is " , best_model_xg.best_score_)
print("Best HyperParameters Are" , best_model_xg.best_estimator_)

"""# Checking Perform improvement with Hyperparameters"""

# LogisticRegression
lr_pipeline=Pipeline([('lr_over' , SMOTE(random_state=45)),
                      ('lr_scalar',StandardScaler()),
                      ('classifier_lr',LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=100,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=None,
                                    solver='saga', tol=0.0001, verbose=0,
                                    warm_start=False))])

# RandomForestClassifier
rf_pipeline=Pipeline([('rf_over' , SMOTE(random_state=45)),
                      ('rf_scalar',StandardScaler()),
                     ('classifier_rf',RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_impurity_split=None,
                                        min_samples_leaf=2, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=200, n_jobs=None,
                                        oob_score=False, random_state=None,
                                        verbose=0, warm_start=False))])
# XGBoostClassifier
xg_pipeline=Pipeline([('xg_over' , SMOTE(random_state=45)),
                      ('xg_scalar',StandardScaler()),
                      ('classifier_xg',XGBClassifier(base_score=0.5, booster='gbtree',
                               colsample_bylevel=1, colsample_bynode=1,
                               colsample_bytree=0.3, gamma=0.0,
                               learning_rate=0.1, max_delta_step=0, max_depth=6,
                               min_child_weight=1, missing=None,
                               n_estimators=100, n_jobs=1, nthread=None,
                               objective='binary:logistic', random_state=0,
                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
                               seed=None, silent=None, subsample=1,
                               verbosity=1))])

## Lets make the list of pipelines
pipelines = [lr_pipeline , rf_pipeline, xg_pipeline]

# Dictionary of pipelines and classifier types for ease of reference
pipe_dict = {0: 'Logistic Regression', 1: 'RandomForest', 2: 'XGBoost'}

# Fit the pipelines
for pipe in pipelines:
	pipe.fit(x_train, y_train)

for i,model in enumerate(pipelines):
    prob=model.predict_proba(x_test)
    score= log_loss(y_test, prob)
    print("{} Log Loss Score : {}".format(pipe_dict[i],score))

for i,model in enumerate(pipelines):
    prob_brier=model.predict_proba(x_test)
    prob_brier=prob_brier[:,1]
    score_brier= brier_score_loss(y_test, prob_brier)
    print("{} Brier Score : {}".format(pipe_dict[i],score_brier))

"""#  score Improvements 

There is Good Improvement in The Log Loss score and Brier Score After HyperParameter Optimization

* And XGBoost Performs Best If Compared With LogisticRegression & RandomForest.
* Final Model will be XGBoost if Considered Log Loss Score AND Brier Score

# **Finding Optimal Threshold**
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, plot_precision_recall_curve

df_train = pd.read_csv('/content/drive/MyDrive/Kaam/preprocessed_Online+offline_bining_used.csv') # Labeled Data 

# Dividing Our Labeled Data  Into Train_Test_Split To Check Model Performance
x=df_train.drop('CHANNEL' , axis = 1)
y=df_train.CHANNEL
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 2)

pipeline=Pipeline([   ('xgg_over' , SMOTE(random_state=45)),
                      ('xgg_scalar',StandardScaler()),
                      ('classifier_xg',XGBClassifier(base_score=0.5, booster='gbtree',
                               colsample_bylevel=1, colsample_bynode=1,
                               colsample_bytree=0.3, gamma=0.0,
                               learning_rate=0.1, max_delta_step=0, max_depth=6,
                               min_child_weight=1, missing=None,
                               n_estimators=100, n_jobs=1, nthread=None,
                               objective='binary:logistic', random_state=0,
                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
                               seed=None, silent=None, subsample=1,
                               verbosity=1))])

pipeline.fit(x_train , y_train)
plot_precision_recall_curve(pipeline, x_test, y_test)

train = pd.read_csv('/content/drive/MyDrive/Kaam/preprocessed_Online+offline_bining_used.csv') # Labeled Data
test = pd.read_csv('/content/drive/MyDrive/Kaam/preprocessed_Validation_offline_customers.csv') # Unlabeled Data

x_train=train.drop('CHANNEL' , axis = 1)
y_train=train.CHANNEL
x_test = test

train.head()

test.head()

print(train.shape)
print(test.shape)

pipeline_xgboost=Pipeline([('xgboost_over' , SMOTE(random_state=45)),
                      ('xgboost_scalar',StandardScaler()),
                      ('classifier_xgboost',XGBClassifier(base_score=0.5, booster='gbtree',
                               colsample_bylevel=1, colsample_bynode=1,
                               colsample_bytree=0.3, gamma=0.0,
                               learning_rate=0.1, max_delta_step=0, max_depth=6,
                               min_child_weight=1, missing=None,
                               n_estimators=100, n_jobs=1, nthread=None,
                               objective='binary:logistic', random_state=0,
                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
                               seed=None, silent=None, subsample=1,
                               verbosity=1))])

pipeline_xgboost.fit(x_train, y_train)
prediction = pipeline_xgboost.predict_proba(x_test)
prediction=pd.DataFrame(prediction)
prediction.columns=['class_0' , 'prediction']
prediction=prediction.drop('class_0' , axis = 1)
prediction=prediction*100
prediction['prediction']=prediction['prediction'].astype(int)

for i in prediction['prediction']:
  if i >=60:
    prediction['prediction']=prediction['prediction'].replace(i , '1')
  else:
    prediction['prediction']=prediction['prediction'].replace(i , '0')

prediction.value_counts()

